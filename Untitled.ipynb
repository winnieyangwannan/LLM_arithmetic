{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56fdfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import transformer_lens\n",
    "from transformer_lens import HookedTransformer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3604ac65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x22eae42bef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51f1cd7f-da74-4d57-9db6-6b9b39344912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\buzlab\\.conda\\envs\\llmtt\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3c945d94984590b0685108a6963277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324649ac1bb6481098d099a8399281e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/24.2G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb2c7ca2f5f4e2494d1973d303ba646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4976a04106cb4800a326d0ab95980ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f8cb55815d475aae349cde12552095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f0b4b5213f46ba9075fdf47fd00dc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a960252045b485791e8d5e7bdc9e908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/4.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb54eaeca0140ccb5c27776163c1e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt-j into HookedTransformer\n",
      "Changing model dtype to torch.bfloat16\n",
      "Moving model to device:  cuda\n"
     ]
    }
   ],
   "source": [
    "model: HookedTransformer = HookedTransformer.from_pretrained(\"gpt-j\", device=\"cpu\")\n",
    "model: HookedTransformer = model.to(torch.bfloat16).to(\"cuda\") # use torch.bfloat16 to save memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "072599c7-b60f-41fa-a8f2-7b7ba99b2881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free(Gb): 0.0 ,total(Gb): 11.81089792\n"
     ]
    }
   ],
   "source": [
    "print(\"free(Gb):\", torch.cuda.mem_get_info()[0]/1000000000, \",total(Gb):\", torch.cuda.mem_get_info()[1]/1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aef17f8-1a60-4aac-8679-0d81da5400af",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = model.cfg.n_layers\n",
    "d_model = model.cfg.d_model\n",
    "n_heads = model.cfg.n_heads\n",
    "d_head = model.cfg.d_head\n",
    "d_mlp = model.cfg.d_mlp\n",
    "d_vocab = model.cfg.d_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d216be8e-b194-4fe3-8cbe-6f93dc865c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', '23', '48', '176', '23', '587', '23', '658', '73', '25', '68', '235']\n",
      "['<|endoftext|>', '123', '+', '456', '=', '579']\n",
      "['<|endoftext|>', '123', '+', '456', '=', '579', '\\n', '9', '13', '+', '72', '=', '985', '\\n', '218', '+', '276', '=', '494']\n"
     ]
    }
   ],
   "source": [
    "print(model.to_str_tokens(\"23481762358723658732568235\"))\n",
    "print(model.to_str_tokens(\"123+456=579\"))\n",
    "print(model.to_str_tokens(\"123+456=579\\n913+72=985\\n218+276=494\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886e3d7-aef5-4dcc-92ac-67246298f543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
